# SceneNet

Scenery detection using transfer learning.

## Description

- Through this app, a user can take a picture of their surrounding to know where they are (could be for fun, could be for emergency, could be for visually impaired people).
- The app uploads the image file to [SceneNet_Backend](https://github.com/Saransh-cpp/SceneNet-Backend), which is trained, using transfer learning, on a dataset of 10,000+ indoor images.
- The API returns a specific category which is then either, ony displayed, or, displayed and spoken (text to speech).
- The user can easily select if they want the app to speak or not.


## Screenshots

<p float="left" align="center">

  <img src="https://user-images.githubusercontent.com/74055102/144904986-22407d8a-92a3-45ae-b175-10943aab3304.png" height=500/>
  <img src="https://user-images.githubusercontent.com/74055102/144904994-472460fc-3761-42b1-abb7-d0dc275da79b.png" height=500/>
  <img src="https://user-images.githubusercontent.com/74055102/144904990-1617b4e3-1c41-4505-80e0-20d87f26922c.png" height=500/>
           
</p>



## Getting Started

This project is a starting point for a Flutter application.

A few resources to get you started if this is your first Flutter project:

- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)
- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)

For help getting started with Flutter, view our
[online documentation](https://flutter.dev/docs), which offers tutorials,
samples, guidance on mobile development, and a full API reference.
